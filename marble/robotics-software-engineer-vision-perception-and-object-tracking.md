# Robotics Software Engineer - Vision, Perception, and Object Tracking
### San Francisco, CA

## Quick Summary
We are a scrappy early-stage robotics startup based in San Francisco. We design, build, and operate autonomous urban delivery robots. In San Francisco alone, hundreds of thousands of packages are delivered every day. Over half of the world’s population lives in cities at least this big. Robotic delivery will improve reliability and drastically reduce the cost of delivery, touching the lives of billions of people and ultimately transforming how the world works. Our team is small and we’re moving lightning fast to create the world’s first fleet of autonomous delivery robots to solve this Earth-scale problem.

## Job Description
Robots delivering packages in a city will encounter every environment imaginable. From people and cars, to traffic cones and broken sidewalks, the robot must operate competently and safely throughout the day. Perception is the key to this competence. In particular, intelligently detecting pedestrians and predicting the behavior of pedestrians and cars is a key challenge. Operating near strange and unexpected hazards like construction is also critically important. We are looking for a lead perception engineer who can develop a system enables planning and behaviors to operate intelligently and safely as the robot drives.

## Qualifications
+ Project or real-world experience with field-deployed perception systems on a mobile robot or other substantial system OR experience with cutting-edge techniques like convolutional neural networks and machine-learning based perception
+ Fluency in C / C++
+ Demonstrated ability to create real time perception algorithms
+ Demonstrated experience in areas like object detection, recognition, tracking, filtering, or prediction
+ Extensive experience with a variety of sensors including LIDAR, cameras, and RADARs
+ Extensive experience with programming and algorithm design
+ Bonus:
   + Experience with deep learning frameworks such as Caffe, Torch, Theano, etc.
   + Masters or PhD in computer science or related degree
   + Experience with autonomous robots
   + Knowledge of computer vision techniques and machine learning
   + Experience with pose estimation, SLAM, probabilistic filtering, and 3D data
